Crea la estructura de carpetas para un proyecto de Machine Learning con datos RAW y procesados, notebook,s modelos una APP de Streamlit, Docs, requirements y un git ignore

importa pandas, numpy, matplotlib, seaborn, scikit-learn, streamlit y Holidays con sus alias mas comunes. Importa las librerías completas. No solo los metodos que se van a usar a corto plazo

Crea un entono pip llamdo Forecasting con Python 3.11 e instala librerias Pandas, Numpy, Matplotlib, Seaborn, Scikit-learn, Jupyter, Streamlit y Holidays para manejar el calendario de España

Desde la carpeta de data/raw/entrenamiento carga los *.csv de ventas y competencias en sus respectivos Dataframes. Ten en cuenta que partes desde la carpeta de notebook para escribir bien sus paths relativos

Valida la calidad de los datos de ventas DF los tipos de cada variable los nulos, los duplicados, los descriptivos, etcetera y muestrame un informe final de calidad de datos


(A raiz de estos datos *copiados al chat) A raiz de estos resultados, tengo que corregir algo en mis datos?
Haz el mismo analisis de calidad con el Dataframe Competencia

Convierte la fecha a Dataframe en ambos Dataframes (Ventas y competencia)
Verifica la conversion de las fechas

Integra df_ventas y df_competencia en un nuevo dataframe llamado df_nuevo usando los campos fecha y producto_id como los campos clave
--
Haz un analisis exploratorio de df_nuevo. Incluye un grafico separado para cada año de lineas temporales con la suma de unidades vendidas para cada año, marcando los black fridays. Luego un grafico de la suma de unidades vendidas por dia de la semana. Otro por categoria, Otro por subcategoria, Otro por los top productos y otro de análisis de la densidad de distribucion de los precios nuestros y los de Amazon como referencia de la competencia. Ve insertando los diferentes análisis en diferentes celidas y que todos los gráficos sean utilizando Seaborn.
--
Pasamos ya a la fase de creacion de variables. Asi que crea las variables temporales usando holidays para España.
Crea por ejemplo, el año, el mes, dia_mes, dia_semana, es_fin_semana, es_festivo, es_Black_Friday, es_Cyber_Monday y otras variables temporales o de calendario que se te ocurran y sean interesantes.

Ahora vamos a crear los lags. Crea los lags de las unidades venididas del lag 1 al lag 7 y crea tambien la media movil de 7 días. Recuerda hacer cada año por separado para no mezclar los ultimos registros de Noviembre de un año con los primeros de octubre del siguiente, y elimina los registros en los que se hayan creado nulos en alguna de las nuevas variables creadas.

Crea una variable de descuento porcentaje como la diferencia entre el precio de venta y el precio base dividido por el precio base y todo multiplicado por 100.

Crea una variable precio_competencia con el precio promedio de los competidores Amazon, Decathlon, deporvillagem y luego crea otra varaible ratio_precio dividiendo nuestro precio entre el precio promedio de la competencia. Finalmente elimina las variables de Amazon, Decathlon, Deporvillage.

--
Crea las variables nombre, categoría y subcategoría añadiendo el sufijo _h en cada una. Luego haz One hot encoding sobre nombre_h, categoria_h y subcategoria_h

Guarda el dataframe df_nuevo procesado en la carpeta data/proccessed
--

divide df_nuevo en df_train con los años 2021 a 2023 y df_validation con el año 2024. Muestrame cuantos registros hay en cada conjunto de datos.

Entrena un HistGradientBoostingRegressor con parámetros conservadores para evitar el sobreajuste: learning_rete bajo, bastantes árboles, profundidad moderada y regularización. 
El objetivo es unidades_vendidas, y las predictoras son el resto de las variables excepto fecha, ingresos y todas las que sean de tipo object. 
Entrena en df_train y valida en df_validation. Calcula las métricas típicas de forecasting y compara contra una linea base naive que predice la media.

Aplica el modelo a los datos de noviembre de 2024 del dataframe nuevo para generar predicciones para cada uno de los 7 productos estrella y crea 7 graficos; uno por cada producto donde se ve la linea de la predicción y la linea de la realidad. Usa el nombre del producto para que sepa de qué producto es cada gráfico.

Aplica el modelo a los datos de noviembre de 2024 del dataframe nuevo para generar predicciones para cada uno de los 7 productos estrella y crea 7 graficos; uno por cada producto donde se ve la linea de la predicción y la linea de la realidad. Usa el nombre del producto para que sepa de qué producto es cada gráfico.

Calcula el MAE para cada uno de los productos estrella

Analiza como degrada el error a lo largo de noviembre de 2024. Divide en 3 periodos de 10 días, calcula métricas por periodo y grafica la evolución

Analiza específicamente Black Friday de 2024 para todos los productos. Crea un grafico real vs la predicción en el eje X estaría el ID de producto y en el eje y una línea para la predicción y otra para la realidad.

Ahora re entrena el modelo final con todos los datos historicos disponibles sobre el DF nuevo. Entrena un nuevo HistGradientBoostingRegressor con los minimos parámetros óptimos y las mismas variables que usaste antes, pero ahora usando el DF nuevo completo desde el 2021 hasta 2024 como conjunto de entrenamiento

Calcula la importancia de variables con permutation importance y el modelo final. Y representala en un gráfico de barras horizontales ordenado de mayor a menor, y guarda el modelo final en la carpeta /models con el nombre modelo_final.joblib


