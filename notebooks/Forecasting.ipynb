{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "021d25bd",
   "metadata": {},
   "source": [
    "# Forecasting de Ventas - Inferencia 2025\n",
    "Este notebook importa las mismas librerías del entrenamiento y carga el archivo `ventas_2025_inferencia` desde `/data/raw/inferencia` en el DataFrame `df_inferencia`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfe4e9d",
   "metadata": {},
   "source": [
    "## 1. Configurar Rutas y Nombre del Notebook\n",
    "Definimos variables de ruta para trabajar en VS Code: carpeta de notebooks (`/notebooks`) y carpeta de datos (`/data/raw/inferencia`), y el nombre del archivo de inferencia (`ventas_2025_inferencia`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f0c36f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ruta notebooks: c:\\Users\\dangmoz\\Forecasting_Ventas\\notebooks\n",
      "Ruta datos inferencia: c:\\Users\\dangmoz\\Forecasting_Ventas\\data\\raw\\inferencia\n",
      "Archivo inferencia: c:\\Users\\dangmoz\\Forecasting_Ventas\\data\\raw\\inferencia\\ventas_2025_inferencia.csv\n"
     ]
    }
   ],
   "source": [
    "# Paths para VS Code (Windows)\n",
    "from pathlib import Path\n",
    "base_dir = Path(r\"c:\\\\Users\\\\dangmoz\\\\Forecasting_Ventas\")\n",
    "notebooks_dir = base_dir / 'notebooks'\n",
    "data_inferencia_dir = base_dir / 'data' / 'raw' / 'inferencia'\n",
    "archivo_inferencia = 'ventas_2025_inferencia.csv'\n",
    "ruta_inferencia = data_inferencia_dir / archivo_inferencia\n",
    "print('Ruta notebooks:', notebooks_dir)\n",
    "print('Ruta datos inferencia:', data_inferencia_dir)\n",
    "print('Archivo inferencia:', ruta_inferencia)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d9fe10",
   "metadata": {},
   "source": [
    "## 2. Importar Librerías (mismas que el notebook de entrenamiento)\n",
    "Replicamos los imports utilizados en el notebook de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f991db4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports cargados: pandas, numpy, matplotlib, seaborn, sklearn, streamlit\n"
     ]
    }
   ],
   "source": [
    "# Imports iguales al notebook de entrenamiento\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import streamlit as st\n",
    "print('Imports cargados: pandas, numpy, matplotlib, seaborn, sklearn, streamlit')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac71608",
   "metadata": {},
   "source": [
    "## 3. Cargar ventas_2025_inferencia en df_inferencia\n",
    "Detectamos automáticamente si el archivo es CSV o Parquet y cargamos en `df_inferencia`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a2238b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferencia cargada: c:\\Users\\dangmoz\\Forecasting_Ventas\\data\\raw\\inferencia\\ventas_2025_inferencia.csv\n"
     ]
    }
   ],
   "source": [
    "# Carga robusta de inferencia (CSV o Parquet)\n",
    "import os\n",
    "df_inferencia = None\n",
    "ext = ruta_inferencia.suffix.lower()\n",
    "if ext == '.csv':\n",
    "    df_inferencia = pd.read_csv(ruta_inferencia, encoding='utf-8')\n",
    "elif ext == '.parquet':\n",
    "    df_inferencia = pd.read_parquet(ruta_inferencia)\n",
    "else:\n",
    "    raise ValueError(f'Formato no soportado: {ext}. Use .csv o .parquet')\n",
    "print('Inferencia cargada:', ruta_inferencia)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865b383b",
   "metadata": {},
   "source": [
    "## 4. Validar Datos Cargados\n",
    "Mostramos shape, primeras filas, tipos de datos y nulos para asegurar compatibilidad con el pipeline de inferencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "503fad38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (888, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fecha</th>\n",
       "      <th>producto_id</th>\n",
       "      <th>nombre</th>\n",
       "      <th>categoria</th>\n",
       "      <th>subcategoria</th>\n",
       "      <th>precio_base</th>\n",
       "      <th>es_estrella</th>\n",
       "      <th>unidades_vendidas</th>\n",
       "      <th>precio_venta</th>\n",
       "      <th>ingresos</th>\n",
       "      <th>Amazon</th>\n",
       "      <th>Decathlon</th>\n",
       "      <th>Deporvillage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-10-25</td>\n",
       "      <td>PROD_001</td>\n",
       "      <td>Nike Air Zoom Pegasus 40</td>\n",
       "      <td>Running</td>\n",
       "      <td>Zapatillas Running</td>\n",
       "      <td>115</td>\n",
       "      <td>True</td>\n",
       "      <td>26.0</td>\n",
       "      <td>113.13</td>\n",
       "      <td>2941.38</td>\n",
       "      <td>89.51</td>\n",
       "      <td>113.43</td>\n",
       "      <td>104.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-10-25</td>\n",
       "      <td>PROD_002</td>\n",
       "      <td>Adidas Ultraboost 23</td>\n",
       "      <td>Running</td>\n",
       "      <td>Zapatillas Running</td>\n",
       "      <td>135</td>\n",
       "      <td>True</td>\n",
       "      <td>27.0</td>\n",
       "      <td>141.89</td>\n",
       "      <td>3831.03</td>\n",
       "      <td>128.73</td>\n",
       "      <td>112.91</td>\n",
       "      <td>122.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-10-25</td>\n",
       "      <td>PROD_003</td>\n",
       "      <td>Asics Gel Nimbus 25</td>\n",
       "      <td>Running</td>\n",
       "      <td>Zapatillas Running</td>\n",
       "      <td>85</td>\n",
       "      <td>False</td>\n",
       "      <td>5.0</td>\n",
       "      <td>85.79</td>\n",
       "      <td>428.95</td>\n",
       "      <td>84.28</td>\n",
       "      <td>74.51</td>\n",
       "      <td>85.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-10-25</td>\n",
       "      <td>PROD_004</td>\n",
       "      <td>New Balance Fresh Foam X 1080v12</td>\n",
       "      <td>Running</td>\n",
       "      <td>Zapatillas Running</td>\n",
       "      <td>75</td>\n",
       "      <td>False</td>\n",
       "      <td>3.0</td>\n",
       "      <td>76.19</td>\n",
       "      <td>228.57</td>\n",
       "      <td>75.54</td>\n",
       "      <td>70.32</td>\n",
       "      <td>71.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-10-25</td>\n",
       "      <td>PROD_005</td>\n",
       "      <td>Nike Dri-FIT Miler</td>\n",
       "      <td>Running</td>\n",
       "      <td>Ropa Running</td>\n",
       "      <td>35</td>\n",
       "      <td>False</td>\n",
       "      <td>3.0</td>\n",
       "      <td>35.48</td>\n",
       "      <td>106.44</td>\n",
       "      <td>33.84</td>\n",
       "      <td>31.32</td>\n",
       "      <td>34.41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        fecha producto_id                            nombre categoria  \\\n",
       "0  2025-10-25    PROD_001          Nike Air Zoom Pegasus 40   Running   \n",
       "1  2025-10-25    PROD_002              Adidas Ultraboost 23   Running   \n",
       "2  2025-10-25    PROD_003               Asics Gel Nimbus 25   Running   \n",
       "3  2025-10-25    PROD_004  New Balance Fresh Foam X 1080v12   Running   \n",
       "4  2025-10-25    PROD_005                Nike Dri-FIT Miler   Running   \n",
       "\n",
       "         subcategoria  precio_base  es_estrella  unidades_vendidas  \\\n",
       "0  Zapatillas Running          115         True               26.0   \n",
       "1  Zapatillas Running          135         True               27.0   \n",
       "2  Zapatillas Running           85        False                5.0   \n",
       "3  Zapatillas Running           75        False                3.0   \n",
       "4        Ropa Running           35        False                3.0   \n",
       "\n",
       "   precio_venta  ingresos  Amazon  Decathlon  Deporvillage  \n",
       "0        113.13   2941.38   89.51     113.43        104.78  \n",
       "1        141.89   3831.03  128.73     112.91        122.88  \n",
       "2         85.79    428.95   84.28      74.51         85.57  \n",
       "3         76.19    228.57   75.54      70.32         71.13  \n",
       "4         35.48    106.44   33.84      31.32         34.41  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tipos de datos:\n",
      "fecha                 object\n",
      "producto_id           object\n",
      "nombre                object\n",
      "categoria             object\n",
      "subcategoria          object\n",
      "precio_base            int64\n",
      "es_estrella             bool\n",
      "unidades_vendidas    float64\n",
      "precio_venta         float64\n",
      "ingresos             float64\n",
      "Amazon               float64\n",
      "Decathlon            float64\n",
      "Deporvillage         float64\n",
      "dtype: object\n",
      "\n",
      "Nulos por columna:\n",
      "fecha                  0\n",
      "producto_id            0\n",
      "nombre                 0\n",
      "categoria              0\n",
      "subcategoria           0\n",
      "precio_base            0\n",
      "es_estrella            0\n",
      "unidades_vendidas    720\n",
      "precio_venta           0\n",
      "ingresos             720\n",
      "Amazon                 0\n",
      "Decathlon              0\n",
      "Deporvillage           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Validaciones básicas del df_inferencia\n",
    "print('Shape:', df_inferencia.shape)\n",
    "display(df_inferencia.head())\n",
    "print('\\nTipos de datos:')\n",
    "print(df_inferencia.dtypes)\n",
    "print('\\nNulos por columna:')\n",
    "print(df_inferencia.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "544fe8c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (888, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fecha</th>\n",
       "      <th>producto_id</th>\n",
       "      <th>nombre</th>\n",
       "      <th>categoria</th>\n",
       "      <th>subcategoria</th>\n",
       "      <th>precio_base</th>\n",
       "      <th>es_estrella</th>\n",
       "      <th>unidades_vendidas</th>\n",
       "      <th>precio_venta</th>\n",
       "      <th>ingresos</th>\n",
       "      <th>Amazon</th>\n",
       "      <th>Decathlon</th>\n",
       "      <th>Deporvillage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-10-25</td>\n",
       "      <td>PROD_001</td>\n",
       "      <td>Nike Air Zoom Pegasus 40</td>\n",
       "      <td>Running</td>\n",
       "      <td>Zapatillas Running</td>\n",
       "      <td>115</td>\n",
       "      <td>True</td>\n",
       "      <td>26.0</td>\n",
       "      <td>113.13</td>\n",
       "      <td>2941.38</td>\n",
       "      <td>89.51</td>\n",
       "      <td>113.43</td>\n",
       "      <td>104.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-10-25</td>\n",
       "      <td>PROD_002</td>\n",
       "      <td>Adidas Ultraboost 23</td>\n",
       "      <td>Running</td>\n",
       "      <td>Zapatillas Running</td>\n",
       "      <td>135</td>\n",
       "      <td>True</td>\n",
       "      <td>27.0</td>\n",
       "      <td>141.89</td>\n",
       "      <td>3831.03</td>\n",
       "      <td>128.73</td>\n",
       "      <td>112.91</td>\n",
       "      <td>122.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-10-25</td>\n",
       "      <td>PROD_003</td>\n",
       "      <td>Asics Gel Nimbus 25</td>\n",
       "      <td>Running</td>\n",
       "      <td>Zapatillas Running</td>\n",
       "      <td>85</td>\n",
       "      <td>False</td>\n",
       "      <td>5.0</td>\n",
       "      <td>85.79</td>\n",
       "      <td>428.95</td>\n",
       "      <td>84.28</td>\n",
       "      <td>74.51</td>\n",
       "      <td>85.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-10-25</td>\n",
       "      <td>PROD_004</td>\n",
       "      <td>New Balance Fresh Foam X 1080v12</td>\n",
       "      <td>Running</td>\n",
       "      <td>Zapatillas Running</td>\n",
       "      <td>75</td>\n",
       "      <td>False</td>\n",
       "      <td>3.0</td>\n",
       "      <td>76.19</td>\n",
       "      <td>228.57</td>\n",
       "      <td>75.54</td>\n",
       "      <td>70.32</td>\n",
       "      <td>71.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-10-25</td>\n",
       "      <td>PROD_005</td>\n",
       "      <td>Nike Dri-FIT Miler</td>\n",
       "      <td>Running</td>\n",
       "      <td>Ropa Running</td>\n",
       "      <td>35</td>\n",
       "      <td>False</td>\n",
       "      <td>3.0</td>\n",
       "      <td>35.48</td>\n",
       "      <td>106.44</td>\n",
       "      <td>33.84</td>\n",
       "      <td>31.32</td>\n",
       "      <td>34.41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        fecha producto_id                            nombre categoria  \\\n",
       "0  2025-10-25    PROD_001          Nike Air Zoom Pegasus 40   Running   \n",
       "1  2025-10-25    PROD_002              Adidas Ultraboost 23   Running   \n",
       "2  2025-10-25    PROD_003               Asics Gel Nimbus 25   Running   \n",
       "3  2025-10-25    PROD_004  New Balance Fresh Foam X 1080v12   Running   \n",
       "4  2025-10-25    PROD_005                Nike Dri-FIT Miler   Running   \n",
       "\n",
       "         subcategoria  precio_base  es_estrella  unidades_vendidas  \\\n",
       "0  Zapatillas Running          115         True               26.0   \n",
       "1  Zapatillas Running          135         True               27.0   \n",
       "2  Zapatillas Running           85        False                5.0   \n",
       "3  Zapatillas Running           75        False                3.0   \n",
       "4        Ropa Running           35        False                3.0   \n",
       "\n",
       "   precio_venta  ingresos  Amazon  Decathlon  Deporvillage  \n",
       "0        113.13   2941.38   89.51     113.43        104.78  \n",
       "1        141.89   3831.03  128.73     112.91        122.88  \n",
       "2         85.79    428.95   84.28      74.51         85.57  \n",
       "3         76.19    228.57   75.54      70.32         71.13  \n",
       "4         35.48    106.44   33.84      31.32         34.41  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tipos de datos:\n",
      "fecha                 object\n",
      "producto_id           object\n",
      "nombre                object\n",
      "categoria             object\n",
      "subcategoria          object\n",
      "precio_base            int64\n",
      "es_estrella             bool\n",
      "unidades_vendidas    float64\n",
      "precio_venta         float64\n",
      "ingresos             float64\n",
      "Amazon               float64\n",
      "Decathlon            float64\n",
      "Deporvillage         float64\n",
      "dtype: object\n",
      "\n",
      "Nulos por columna:\n",
      "fecha                  0\n",
      "producto_id            0\n",
      "nombre                 0\n",
      "categoria              0\n",
      "subcategoria           0\n",
      "precio_base            0\n",
      "es_estrella            0\n",
      "unidades_vendidas    720\n",
      "precio_venta           0\n",
      "ingresos             720\n",
      "Amazon                 0\n",
      "Decathlon              0\n",
      "Deporvillage           0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dangmoz\\AppData\\Local\\Temp\\ipykernel_6676\\675448645.py:44: FutureWarning: The behavior of 'isin' with dtype=datetime64[ns] and castable values (e.g. strings) is deprecated. In a future version, these will not be considered matching by isin. Explicitly cast to the appropriate dtype before calling isin instead.\n",
      "  df_inferencia['es_festivo'] = df_inferencia['fecha'].isin(festivos_es)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros originales: 888, noviembre: 720\n",
      "df_inferencia transformado (noviembre) guardado en: ..\\data\\processed\\df_inferencia_transformado.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fecha</th>\n",
       "      <th>producto_id</th>\n",
       "      <th>subcategoria</th>\n",
       "      <th>precio_base</th>\n",
       "      <th>es_estrella</th>\n",
       "      <th>unidades_vendidas</th>\n",
       "      <th>precio_venta</th>\n",
       "      <th>ingresos</th>\n",
       "      <th>año</th>\n",
       "      <th>mes</th>\n",
       "      <th>...</th>\n",
       "      <th>nombre_h_Quechua MH500</th>\n",
       "      <th>nombre_h_Reebok Floatride Energy 5</th>\n",
       "      <th>nombre_h_Reebok Professional Deck</th>\n",
       "      <th>nombre_h_Salomon Speedcross 5 GTX</th>\n",
       "      <th>nombre_h_Sveltus Kettlebell 12kg</th>\n",
       "      <th>nombre_h_The North Face Borealis</th>\n",
       "      <th>nombre_h_Trek Marlin 7</th>\n",
       "      <th>precio_venta_lag_1</th>\n",
       "      <th>precio_venta_lag_7</th>\n",
       "      <th>precio_venta_lag_14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>2025-11-01</td>\n",
       "      <td>PROD_001</td>\n",
       "      <td>Zapatillas Running</td>\n",
       "      <td>115</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>115.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>110.93</td>\n",
       "      <td>113.13</td>\n",
       "      <td>115.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>2025-11-02</td>\n",
       "      <td>PROD_001</td>\n",
       "      <td>Zapatillas Running</td>\n",
       "      <td>115</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>115.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>115.00</td>\n",
       "      <td>105.75</td>\n",
       "      <td>115.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>2025-11-03</td>\n",
       "      <td>PROD_001</td>\n",
       "      <td>Zapatillas Running</td>\n",
       "      <td>115</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>115.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>115.00</td>\n",
       "      <td>114.95</td>\n",
       "      <td>115.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>2025-11-04</td>\n",
       "      <td>PROD_001</td>\n",
       "      <td>Zapatillas Running</td>\n",
       "      <td>115</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>115.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>115.00</td>\n",
       "      <td>117.31</td>\n",
       "      <td>115.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>2025-11-05</td>\n",
       "      <td>PROD_001</td>\n",
       "      <td>Zapatillas Running</td>\n",
       "      <td>115</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>115.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>115.00</td>\n",
       "      <td>108.10</td>\n",
       "      <td>115.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         fecha producto_id        subcategoria  precio_base  es_estrella  \\\n",
       "168 2025-11-01    PROD_001  Zapatillas Running          115         True   \n",
       "192 2025-11-02    PROD_001  Zapatillas Running          115         True   \n",
       "216 2025-11-03    PROD_001  Zapatillas Running          115         True   \n",
       "240 2025-11-04    PROD_001  Zapatillas Running          115         True   \n",
       "264 2025-11-05    PROD_001  Zapatillas Running          115         True   \n",
       "\n",
       "     unidades_vendidas  precio_venta  ingresos   año  mes  ...  \\\n",
       "168                NaN         115.0       NaN  2025   11  ...   \n",
       "192                NaN         115.0       NaN  2025   11  ...   \n",
       "216                NaN         115.0       NaN  2025   11  ...   \n",
       "240                NaN         115.0       NaN  2025   11  ...   \n",
       "264                NaN         115.0       NaN  2025   11  ...   \n",
       "\n",
       "     nombre_h_Quechua MH500  nombre_h_Reebok Floatride Energy 5  \\\n",
       "168                       0                                   0   \n",
       "192                       0                                   0   \n",
       "216                       0                                   0   \n",
       "240                       0                                   0   \n",
       "264                       0                                   0   \n",
       "\n",
       "     nombre_h_Reebok Professional Deck  nombre_h_Salomon Speedcross 5 GTX  \\\n",
       "168                                  0                                  0   \n",
       "192                                  0                                  0   \n",
       "216                                  0                                  0   \n",
       "240                                  0                                  0   \n",
       "264                                  0                                  0   \n",
       "\n",
       "     nombre_h_Sveltus Kettlebell 12kg  nombre_h_The North Face Borealis  \\\n",
       "168                                 0                                 0   \n",
       "192                                 0                                 0   \n",
       "216                                 0                                 0   \n",
       "240                                 0                                 0   \n",
       "264                                 0                                 0   \n",
       "\n",
       "     nombre_h_Trek Marlin 7  precio_venta_lag_1  precio_venta_lag_7  \\\n",
       "168                       0              110.93              113.13   \n",
       "192                       0              115.00              105.75   \n",
       "216                       0              115.00              114.95   \n",
       "240                       0              115.00              117.31   \n",
       "264                       0              115.00              108.10   \n",
       "\n",
       "     precio_venta_lag_14  \n",
       "168                115.0  \n",
       "192                115.0  \n",
       "216                115.0  \n",
       "240                115.0  \n",
       "264                115.0  \n",
       "\n",
       "[5 rows x 63 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas del modelo (noviembre): 118\n",
      "precio_base       int64\n",
      "es_estrella        bool\n",
      "precio_venta    float64\n",
      "dia_semana        int32\n",
      "año               int32\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# ...existing code...\n",
    "# Validaciones básicas del df_inferencia\n",
    "print('Shape:', df_inferencia.shape)\n",
    "display(df_inferencia.head())\n",
    "print('\\nTipos de datos:')\n",
    "print(df_inferencia.dtypes)\n",
    "print('\\nNulos por columna:')\n",
    "print(df_inferencia.isnull().sum())\n",
    "# ...existing code...\n",
    "\n",
    "# === 5. Transformaciones idénticas a Entrenamiento para df_inferencia ===\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# Asegurar tipos y columnas mínimas esperadas\n",
    "# Se espera al menos: 'fecha', 'producto_id', 'precio_venta', 'precio_base'\n",
    "# Competencia opcional: 'Amazon', 'Decathlon', 'Deporvillage'\n",
    "# Ventas/target como referencia (no se usa para inferencia): 'unidades_vendidas', 'ingresos'\n",
    "if 'fecha' not in df_inferencia.columns:\n",
    "    raise ValueError(\"df_inferencia debe contener la columna 'fecha'\")\n",
    "# Parseo de fecha\n",
    "df_inferencia['fecha'] = pd.to_datetime(df_inferencia['fecha'])\n",
    "\n",
    "# ===== Calendario y variables temporales (ver Entrenamiento.ipynb secciones 2065-2116) =====\n",
    "# Año, mes, día, día de semana, nombre de día, semana ISO\n",
    "df_inferencia['año'] = df_inferencia['fecha'].dt.year\n",
    "df_inferencia['mes'] = df_inferencia['fecha'].dt.month\n",
    "df_inferencia['dia_mes'] = df_inferencia['fecha'].dt.day\n",
    "df_inferencia['dia_semana'] = df_inferencia['fecha'].dt.dayofweek\n",
    "df_inferencia['nombre_dia_semana'] = df_inferencia['fecha'].dt.day_name()\n",
    "df_inferencia['semana_año'] = df_inferencia['fecha'].dt.isocalendar().week\n",
    "\n",
    "# Trimestre, fin de semana\n",
    "df_inferencia['trimestre'] = df_inferencia['fecha'].dt.quarter\n",
    "df_inferencia['es_fin_semana'] = df_inferencia['dia_semana'].isin([5, 6])\n",
    "\n",
    "# Festivos España usando holidays (igual que entrenamiento)\n",
    "try:\n",
    "    import holidays\n",
    "    from datetime import timedelta\n",
    "    festivos_es = holidays.country_holidays('ES', years=df_inferencia['año'].unique())\n",
    "    df_inferencia['es_festivo'] = df_inferencia['fecha'].isin(festivos_es)\n",
    "except Exception:\n",
    "    # Si no está disponible holidays, marcar False para evitar fallo\n",
    "    df_inferencia['es_festivo'] = False\n",
    "\n",
    "# Black Friday: último viernes de noviembre del año\n",
    "def es_black_friday(fecha: pd.Timestamp) -> bool:\n",
    "    nov = fecha.replace(month=11, day=1)\n",
    "    dias_nov = [nov + pd.Timedelta(days=i) for i in range(0, 30)]\n",
    "    viernes_nov = [d for d in dias_nov if d.weekday() == 4]\n",
    "    ultimo_viernes = max(viernes_nov) if viernes_nov else None\n",
    "    return bool(ultimo_viernes and fecha == ultimo_viernes)\n",
    "\n",
    "df_inferencia['es_black_friday'] = df_inferencia['fecha'].apply(es_black_friday)\n",
    "\n",
    "# Inicio/fin de mes y trimestre, estaciones, navidad (24-26 dic)\n",
    "df_inferencia['es_fin_mes'] = df_inferencia['fecha'] == (df_inferencia['fecha'] + pd.offsets.MonthEnd(0))\n",
    "df_inferencia['es_inicio_trimestre'] = df_inferencia['mes'].isin([1, 4, 7, 10]) & (df_inferencia['dia_mes'] == 1)\n",
    "df_inferencia['es_fin_trimestre'] = df_inferencia['mes'].isin([3, 6, 9, 12]) & (df_inferencia['fecha'] == (df_inferencia['fecha'] + pd.offsets.MonthEnd(0)))\n",
    "df_inferencia['es_verano'] = df_inferencia['mes'].isin([6, 7, 8])\n",
    "df_inferencia['es_navidad'] = df_inferencia['mes'].eq(12) & df_inferencia['dia_mes'].isin([24, 25, 26])\n",
    "\n",
    "# ===== Ingeniería de precio/competencia (ver Entrenamiento.ipynb línea 2532) =====\n",
    "# descuento_porcentaje = (precio_venta - precio_base) / precio_base * 100\n",
    "if {'precio_venta', 'precio_base'}.issubset(df_inferencia.columns):\n",
    "    base_nonzero = df_inferencia['precio_base'].replace(0, np.nan)\n",
    "    df_inferencia['descuento_porcentaje'] = ((df_inferencia['precio_venta'] - df_inferencia['precio_base']) / base_nonzero) * 100\n",
    "    df_inferencia['descuento_porcentaje'] = df_inferencia['descuento_porcentaje'].fillna(0.0)\n",
    "else:\n",
    "    df_inferencia['descuento_porcentaje'] = 0.0\n",
    "\n",
    "competidores = ['Amazon', 'Decathlon', 'Deporvillage']\n",
    "comp_cols_present = [c for c in competidores if c in df_inferencia.columns]\n",
    "if comp_cols_present:\n",
    "    df_inferencia['precio_competencia'] = df_inferencia[comp_cols_present].mean(axis=1)\n",
    "    # ratio_precio = nuestro precio / precio competencia\n",
    "    denom = df_inferencia['precio_competencia'].replace(0, np.nan)\n",
    "    if 'precio_venta' in df_inferencia.columns:\n",
    "        df_inferencia['ratio_precio'] = df_inferencia['precio_venta'] / denom\n",
    "    else:\n",
    "        df_inferencia['ratio_precio'] = np.nan\n",
    "    # Eliminar columnas originales de competidores para alinear con entrenamiento\n",
    "    df_inferencia = df_inferencia.drop(columns=comp_cols_present)\n",
    "else:\n",
    "    # Si no hay columnas de competidores en inferencia, crear columnas vacías usadas en entrenamiento\n",
    "    df_inferencia['precio_competencia'] = np.nan\n",
    "    df_inferencia['ratio_precio'] = np.nan\n",
    "\n",
    "# ===== One-Hot Encoding similar a entrenamiento =====\n",
    "# En Entrenamiento se aplicó OHE a variables de texto/temporales (se observan columnas *_h_ en la sección 2861).\n",
    "# Aquí OHE para 'nombre_dia_semana' y, si existen, 'categoria', 'nombre' u otras categóricas no numéricas.\n",
    "ohe_cols_candidates = []\n",
    "if 'nombre_dia_semana' in df_inferencia.columns:\n",
    "    ohe_cols_candidates.append('nombre_dia_semana')\n",
    "for c in ['categoria', 'nombre']:\n",
    "    if c in df_inferencia.columns and df_inferencia[c].dtype == 'object':\n",
    "        ohe_cols_candidates.append(c)\n",
    "\n",
    "if ohe_cols_candidates:\n",
    "    dummies = pd.get_dummies(df_inferencia[ohe_cols_candidates], prefix=[f\"{c}_h\" for c in ohe_cols_candidates], dtype=int)\n",
    "    df_inferencia = pd.concat([df_inferencia.drop(columns=ohe_cols_candidates), dummies], axis=1)\n",
    "\n",
    "# ===== (Opcional) Lags básicos si están definidos por producto y fecha =====\n",
    "# En Entrenamiento se construyó df_nuevo_lags. Para inferencia mensual 2025, si existen columnas de serie,\n",
    "# podemos crear lags mínimos sobre precio_venta por producto.\n",
    "if {'producto_id', 'fecha', 'precio_venta'}.issubset(df_inferencia.columns):\n",
    "    df_inferencia = df_inferencia.sort_values(['producto_id', 'fecha'])\n",
    "    df_inferencia['precio_venta_lag_1'] = df_inferencia.groupby('producto_id')['precio_venta'].shift(1)\n",
    "    df_inferencia['precio_venta_lag_7'] = df_inferencia.groupby('producto_id')['precio_venta'].shift(7)\n",
    "    df_inferencia['precio_venta_lag_14'] = df_inferencia.groupby('producto_id')['precio_venta'].shift(14)\n",
    "    # Relleno conservador\n",
    "    for c in ['precio_venta_lag_1', 'precio_venta_lag_7', 'precio_venta_lag_14']:\n",
    "        df_inferencia[c] = df_inferencia[c].fillna(df_inferencia['precio_venta'])\n",
    "\n",
    "# ===== Alinear columnas con las usadas en entrenamiento =====\n",
    "models_dir = Path(\"../models\")\n",
    "features_full_path = models_dir / \"histgb_features_full.json\"\n",
    "if features_full_path.exists():\n",
    "    with open(features_full_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        features_json = json.load(f)\n",
    "    feature_cols = features_json.get('features', [])\n",
    "else:\n",
    "    # Fallback: usar las columnas numéricas no objetivo\n",
    "    feature_cols = list(df_inferencia.select_dtypes(exclude=['object']).columns)\n",
    "\n",
    "# Eliminar columnas que no se usan para el modelo (iguales a entrenamiento)\n",
    "exclude_cols = ['fecha', 'ingresos', 'unidades_vendidas']\n",
    "df_model = df_inferencia.drop(columns=[c for c in exclude_cols if c in df_inferencia.columns])\n",
    "\n",
    "# Mantener solo numéricas\n",
    "df_model = df_model.select_dtypes(exclude=['object'])\n",
    "\n",
    "# Alinear orden y rellenar faltantes de columnas esperadas por el modelo\n",
    "for col in feature_cols:\n",
    "    if col not in df_model.columns:\n",
    "        # Crear columna faltante con 0 (o NaN y luego permitir imputación del modelo si aplica)\n",
    "        df_model[col] = 0\n",
    "# Quitar columnas extra no presentes en el modelo\n",
    "df_model = df_model[feature_cols]\n",
    "\n",
    "# ===== Filtrar solo noviembre y eliminar octubre =====\n",
    "# Mantener el índice con las filas originales para posible trazabilidad\n",
    "if 'mes' not in df_inferencia.columns:\n",
    "    df_inferencia['mes'] = df_inferencia['fecha'].dt.month\n",
    "\n",
    "mask_noviembre = df_inferencia['mes'] == 11\n",
    "df_inferencia_nov = df_inferencia.loc[mask_noviembre].copy()\n",
    "df_model_nov = df_model.loc[mask_noviembre].copy()\n",
    "\n",
    "print(f\"Registros originales: {len(df_inferencia)}, noviembre: {len(df_inferencia_nov)}\")\n",
    "\n",
    "# ===== Guardar df_inferencia transformado (estructura completa + columnas del modelo) =====\n",
    "processed_dir = Path(\"../data/processed\")\n",
    "processed_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Guardamos la versión transformada completa para trazabilidad\n",
    "out_path = processed_dir / \"df_inferencia_transformado.csv\"\n",
    "df_inferencia_nov.to_csv(out_path, index=False, encoding='utf-8')\n",
    "print(f\"df_inferencia transformado (noviembre) guardado en: {out_path}\")\n",
    "\n",
    "# Opcional: mostrar preview\n",
    "display(df_inferencia_nov.head())\n",
    "print(\"Columnas del modelo (noviembre):\", len(df_model_nov.columns))\n",
    "print(df_model_nov.dtypes.head())\n",
    "# ...existing code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9982af76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cuantos elementos diferentes de producto_id hay en df_inferencia. Cuantos productos son unicos?\n",
    "df_inferencia.producto_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994ece68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fecha', 'producto_id', 'subcategoria', 'precio_base', 'es_estrella',\n",
       "       'unidades_vendidas', 'precio_venta', 'ingresos', 'año', 'mes',\n",
       "       'dia_mes', 'dia_semana', 'semana_año', 'trimestre', 'es_fin_semana',\n",
       "       'es_festivo', 'es_black_friday', 'es_fin_mes', 'es_inicio_trimestre',\n",
       "       'es_fin_trimestre', 'es_verano', 'es_navidad', 'descuento_porcentaje',\n",
       "       'precio_competencia', 'ratio_precio', 'nombre_dia_semana_h_Friday',\n",
       "       'nombre_dia_semana_h_Monday', 'nombre_dia_semana_h_Saturday',\n",
       "       'nombre_dia_semana_h_Sunday', 'nombre_dia_semana_h_Thursday',\n",
       "       'nombre_dia_semana_h_Tuesday', 'nombre_dia_semana_h_Wednesday',\n",
       "       'categoria_h_Fitness', 'categoria_h_Outdoor', 'categoria_h_Running',\n",
       "       'categoria_h_Wellness', 'nombre_h_Adidas Own The Run Jacket',\n",
       "       'nombre_h_Adidas Ultraboost 23', 'nombre_h_Asics Gel Nimbus 25',\n",
       "       'nombre_h_Bowflex SelectTech 552', 'nombre_h_Columbia Silver Ridge',\n",
       "       'nombre_h_Decathlon Bandas Elásticas Set', 'nombre_h_Domyos BM900',\n",
       "       'nombre_h_Domyos Kit Mancuernas 20kg',\n",
       "       'nombre_h_Gaiam Premium Yoga Block', 'nombre_h_Liforme Yoga Pad',\n",
       "       'nombre_h_Lotuscrafts Yoga Bolster', 'nombre_h_Manduka PRO Yoga Mat',\n",
       "       'nombre_h_Merrell Moab 2 GTX',\n",
       "       'nombre_h_New Balance Fresh Foam X 1080v12',\n",
       "       'nombre_h_Nike Air Zoom Pegasus 40', 'nombre_h_Nike Dri-FIT Miler',\n",
       "       'nombre_h_Puma Velocity Nitro 2', 'nombre_h_Quechua MH500',\n",
       "       'nombre_h_Reebok Floatride Energy 5',\n",
       "       'nombre_h_Reebok Professional Deck',\n",
       "       'nombre_h_Salomon Speedcross 5 GTX', 'nombre_h_Sveltus Kettlebell 12kg',\n",
       "       'nombre_h_The North Face Borealis', 'nombre_h_Trek Marlin 7',\n",
       "       'precio_venta_lag_1', 'precio_venta_lag_7', 'precio_venta_lag_14'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "df_inferencia.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5e6c1d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cuantos elementos diferentes de fecha hay en df_inferencia\n",
    "df_inferencia.fecha.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8e3e22d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(888, 63)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cantidad de registros en df_inferencia\n",
    "df_inferencia.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55ec174",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "98f67d82",
   "metadata": {},
   "source": [
    "## 5. Conteo de valores nulos en noviembre\n",
    "Calculamos cuántos valores nulos hay en el DataFrame de inferencia filtrado a noviembre y el detalle por columna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "563cfbba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros en noviembre: 720\n",
      "Total de valores nulos en noviembre: 1440\n",
      "Columnas con al menos un nulo: 2\n",
      "Filas con al menos un nulo: 720\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nulos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>unidades_vendidas</th>\n",
       "      <td>720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ingresos</th>\n",
       "      <td>720</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   nulos\n",
       "unidades_vendidas    720\n",
       "ingresos             720"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Conteo de nulos para el mes de noviembre\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Usar df_inferencia_nov si ya fue creado; si no, filtrarlo ahora\n",
    "if 'df_inferencia_nov' in globals():\n",
    "    df_nov = df_inferencia_nov.copy()\n",
    "else:\n",
    "    if 'df_inferencia' not in globals():\n",
    "        raise NameError('df_inferencia no está disponible. Ejecuta las celdas de carga primero.')\n",
    "    if 'fecha' not in df_inferencia.columns:\n",
    "        raise KeyError(\"La columna 'fecha' no existe en df_inferencia.\")\n",
    "    # Asegurar tipo datetime y filtrar noviembre\n",
    "    df_tmp = df_inferencia.copy()\n",
    "    if not pd.api.types.is_datetime64_any_dtype(df_tmp['fecha']):\n",
    "        df_tmp['fecha'] = pd.to_datetime(df_tmp['fecha'])\n",
    "    df_tmp['mes'] = df_tmp['fecha'].dt.month\n",
    "    df_nov = df_tmp[df_tmp['mes'] == 11].copy()\n",
    "\n",
    "total_nulos = int(df_nov.isnull().sum().sum())\n",
    "nulos_por_col = df_nov.isnull().sum().sort_values(ascending=False)\n",
    "columnas_con_nulos = int((nulos_por_col > 0).sum())\n",
    "filas_con_alguna_na = int(df_nov.isnull().any(axis=1).sum())\n",
    "\n",
    "print(f'Registros en noviembre: {len(df_nov)}')\n",
    "print(f'Total de valores nulos en noviembre: {total_nulos}')\n",
    "print(f'Columnas con al menos un nulo: {columnas_con_nulos}')\n",
    "print(f'Filas con al menos un nulo: {filas_con_alguna_na}')\n",
    "\n",
    "# Mostrar detalle de columnas con nulos (si existen)\n",
    "nulos_detalle = nulos_por_col[nulos_por_col > 0]\n",
    "if not nulos_detalle.empty:\n",
    "    display(nulos_detalle.to_frame('nulos'))\n",
    "else:\n",
    "    print('No se encontraron columnas con nulos en noviembre.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
